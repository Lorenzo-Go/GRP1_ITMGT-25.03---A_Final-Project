{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5e1bca8-9ee3-41f1-9940-a5de9e7f5b97",
   "metadata": {},
   "source": [
    "# End-of-Module Assessment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11d77fc-3832-4b39-aee7-8f8014464ac1",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Please read and follow these instructions and specifications carefully.  \n",
    "\n",
    "1. This test is available from now until August 6 (Friday), 11:59 PM.\n",
    "2. This test covers Module 5, which is about data analysis using libraries. However, you will need fundamental skills from Modules 2 to 4 to do this test properly.\n",
    "3. This test is by project group. \n",
    "4. You are allowed to use the specified non-standard libraries for this test: `pandas`, `numpy`, and `matplotlib`. You are allowed to use any standard library for this test.\n",
    "5. Answers to problems that are hard-coded, done in another program such as Excel, or go against the learning outcomes in any other manner will be given no credit. If you are unsure whether your approach to a problem goes against the learning outcomes, ask.  \n",
    "6. We reserve the right to scrutinize answers to problems that significantly go against the philosophy of a library. For example, if you answer a Pandas item mostly using vanilla Python loops and data structures, you go against the philosophy of Pandas (and NumPy), which is to _vectorize_ your operations as much as you can. We reserve the right to scrutinize your answer accordingly.\n",
    "7. You are encouraged to use only the provided code cell for each number. However, if you _need_ more cells, you may add them. If you do add more cells, make sure to label them very clearly. Code cells that are not clearly labelled will not be checked.\n",
    "8. If you are asked to output files, please write them all to the `output` folder. If your kit does not have an `output` folder, you may make one.\n",
    "\n",
    "Submission instructions for normal (i.e., not cross-section) groups:\n",
    "1. Assign a group leader. The leader is who will submit the assessment.\n",
    "2. The leader must create a NEW GitHub repository. This repository is what they will submit to the Canvas assignment to indicate that the group has submitted. They should name this repository SECTION-GROUPNUM-EOMA2 (e.g., A-5-EOMA2).\n",
    "3. The leader must upload the contents of this folder to the repository. This includes the EOMA2.ipynb file, the output folder, and all section folders.\n",
    "4. To officially submit the assignment, the group leader must upload the link to the GitHub repository and ALL GROUP MEMBERS' COAs to the Canvas assignment.\n",
    "\n",
    "Submission instructions for cross-section groups:\n",
    "1. Assign a group leader. The leader is who will create the GitHub repository, and they are who will add the required files to the GitHub repository. \n",
    "2. The leader must create a NEW GitHub repository. They should name this repository GROUPNAME-EOMA2 (e.g., CS1-EOMA2). \n",
    "3. The leader must upload the contents of this folder to the repository. This includes the EOMA2.ipynb file, the output folder, and all section folders.\n",
    "4. Since your group is split across sections, your group must choose one member per represented section to submit the exact same file kit to their respective section's Canvas assignment. For example, if all sections (A, G, and H) are represented in your group, choose one person per section (i.e., 3 people) to submit your EOMA2 submission to their respective section's Canvas assignment. If only two sections are represented, then only 2 submissions (i.e., one per represented section, so in this case 2) must be submitted. Please note that we will quite literally not give a grade to students in cross-section groups who are not represented by a submission for their section. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1beffe5-e110-490b-99dd-f0fdb83a935f",
   "metadata": {},
   "source": [
    "## Section 2: Cleaning Marketing Data (75 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f348b81f-1959-4b4d-a585-f605232fedb3",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "You are a freelance data consultant. You were hired by a marketing firm that collects customer data for their clients, which are big fast-moving-consumer-goods (FMCG) firms. Your client, the marketing firm, currently handles their operations through a \"multi-channel\" approach. (To grossly oversimplify, a multi-channel approach to marketing means that a brand can interact with customers across more than one channel). However, they would like to upgrade their system to use an \"omni-channel\" approach. (An omni-channel approach means that a customer can be recognized across multiple channels. This is important because you will be able to personalize their experience better.)  \n",
    "\n",
    "Your client currently has three main data sets:  \n",
    "1. Manual interaction (`./section2/raw-manual.csv`)\n",
    "2. Website interaction (`./section2/raw-website.csv`)\n",
    "3. Email interaction (`./section2/raw-email.csv`)\n",
    "\n",
    "They task you with cleaning and merging their data to help them establish their omni-channel capabilities.  \n",
    "\n",
    "Again, you are to use Pandas for this, because your client's real databases are much, much bigger than these samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861cb98-63fb-4b18-befb-98ffd95ebf5a",
   "metadata": {},
   "source": [
    "### 2.1\n",
    "\n",
    "Your client first asks you to clean up their data. They want their data to follow these rules:  \n",
    "1. Emails must not have any capital letters.  \n",
    "2. Mobile numbers must be formatted as `+63XXXXXXXXXX` (e.g., +639174005892).\n",
    "3. All the fields (fname, lname, email, and mobile) must be filled.\n",
    "4. The fields must only contain data relevant to them; they must not contain data that does not belong in their column.\n",
    "\n",
    "You have surveyed the data a little, and you have determined that though the data is dirty, it at least adheres to the following patterns:\n",
    "1. All of the emails adhere to the email standard at https://emailregex.com/. (That's a hint.)\n",
    "2. There are only 4 different \"patterns\" under the `mobile` columns per data set. (An empty field is not one of these 4 patterns).\n",
    "3. The manual data set appears to have sometimes merged the `email` value and the `mobile` value into the `email` column and left the `mobile` column empty. The mobile value in these defective columns may be any one of the 4 different \"patterns\" that mobile numbers follow.  \n",
    "\n",
    "Perform this cleanup on each of the three raw data sets.  \n",
    "\n",
    "Save the cleaned data sets as `./output/cleaned-{dataset_name}.csv`. So, for example, `./section2/raw-manual.csv` will be cleaned and saved as `./output/cleaned-manual.csv`.  \n",
    "\n",
    "Do not include the dataframe index in the output csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a184436b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 1 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a29047c28b7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#copy new df columns to old df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mmanual_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nemail'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_manual_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmanual_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nmobile'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_manual_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#remove NaN/NA and combine 2 mobile columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "# CODE CELL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re # That's a hint.\n",
    "\n",
    "# CODE START\n",
    "\n",
    "# ------------------------------------------------- MANUAL ----------------------------------------------------\n",
    "\n",
    "filename = \"./section2/raw-manual.csv\"\n",
    "manual_df = pd.read_csv(filename)\n",
    "\n",
    "#COLUMNS \n",
    "#convert to string\n",
    "manual_df = manual_df.astype({\"email\": str})\n",
    "\n",
    "#split the emails to new df\n",
    "new_manual_df = manual_df['email'].str.split(\"/\", n = 1, expand = True)\n",
    "\n",
    "#copy new df columns to old df\n",
    "manual_df['nemail']=new_manual_df[0]\n",
    "manual_df['nmobile']=new_manual_df[1]\n",
    "\n",
    "#remove NaN/NA and combine 2 mobile columns\n",
    "manual_df['fmobile'] = manual_df['mobile'].fillna('') + manual_df['nmobile'].fillna('')\n",
    "\n",
    "#remove extra columns\n",
    "manual_df.drop(columns=['email', 'mobile', 'nmobile'], inplace=True)\n",
    "\n",
    "#rename columns\n",
    "manual_df['email']=manual_df['nemail']\n",
    "manual_df['mobile']=manual_df['fmobile']\n",
    "\n",
    "#rearrange columns\n",
    "cols = ['email', 'fname', 'lname', 'mobile']\n",
    "manual_df = manual_df[cols]\n",
    "\n",
    "#EMAILS\n",
    "#convert to string\n",
    "manual_df = manual_df.astype({\"email\": 'string'})\n",
    "\n",
    "#capitalize emails\n",
    "manual_df['email']=manual_df['email'].str.replace(r\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\",\n",
    "                                              lambda x:x.group(0).lower())\n",
    "\n",
    "#NUMBERS\n",
    "manual_df.mobile = manual_df.mobile.str.replace(' ', '')\n",
    "manual_df.mobile=np.where(manual_df.mobile.str.startswith('63'),'+' + manual_df.mobile,manual_df.mobile)\n",
    "manual_df.mobile=np.where(manual_df.mobile.str.startswith('09'),'+63'+ \n",
    "manual_df.mobile.str[1:],manual_df.mobile)\n",
    "manual_df.mobile=np.where(manual_df.mobile.str.startswith('9'),'+63'+ manual_df.mobile,manual_df.mobile)\n",
    "\n",
    "#CSV FILE\n",
    "manual_df.to_csv(\"./output/cleaned-manual.csv\", index=False)\n",
    "\n",
    "\n",
    "# ------------------------------------------------- WEBSITE ----------------------------------------------------\n",
    "filename = \"./section2/raw-website.csv\"\n",
    "website_df = pd.read_csv(filename)\n",
    "\n",
    "#EMAILS\n",
    "#Convert to String\n",
    "website_df = website_df.astype({\"email\": 'string'})\n",
    "\n",
    "#Capitalize Emails\n",
    "website_df['email']=website_df['email'].str.replace(r\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\",\n",
    "                                              lambda x:x.group(0).lower())\n",
    "\n",
    "#NUMBERS\n",
    "website_df.mobile = website_df.mobile.str.replace(' ', '')\n",
    "website_df.mobile=np.where(website_df.mobile.str.startswith('63'),'+' + website_df.mobile,website_df.mobile)\n",
    "website_df.mobile=np.where(website_df.mobile.str.startswith('09'),'+63'+ \n",
    "website_df.mobile.str[1:],website_df.mobile)\n",
    "website_df.mobile=np.where(website_df.mobile.str.startswith('9'),'+63'+ website_df.mobile,website_df.mobile)\n",
    "\n",
    "#CSV \n",
    "website_df.to_csv(\"./output/cleaned-website.csv\", index=False)\n",
    "\n",
    "# ------------------------------------------------- EMAILS ----------------------------------------------------\n",
    "\n",
    "filename = \"./section2/raw-email.csv\"\n",
    "email_df = pd.read_csv(filename)\n",
    "email_df  \n",
    "\n",
    "#EMAILS\n",
    "#Convert to String\n",
    "email_df = email_df.astype({\"email\": 'string'})\n",
    "\n",
    "#Capitalize Emails\n",
    "email_df['email']=email_df['email'].str.replace(r\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\",\n",
    "                                              lambda x:x.group(0).lower())\n",
    "\n",
    "#NUMBERS\n",
    "email_df.mobile = email_df.mobile.str.replace(' ', '')\n",
    "email_df.mobile=np.where(email_df.mobile.str.startswith('63'),'+' + email_df.mobile,email_df.mobile)\n",
    "email_df.mobile=np.where(email_df.mobile.str.startswith('09'),'+63'+ \n",
    "email_df.mobile.str[1:],email_df.mobile)\n",
    "email_df.mobile=np.where(email_df.mobile.str.startswith('9'),'+63'+ email_df.mobile,email_df.mobile)\n",
    "\n",
    "#test \n",
    "email_df.to_csv(\"./output/cleaned-email.csv\", index=False)\n",
    "\n",
    "# CODE END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157e2788-6360-4b22-acd1-f831606288a7",
   "metadata": {},
   "source": [
    "### 2.2\n",
    "\n",
    "Your client wants you to generate a comprehensive list of the identities present in their scattered data. Their specifications are as follows:\n",
    "1. Use the cleaned data from 2.1 as your data source.\n",
    "2. Use the emails as the indicator of a unique identity.\n",
    "3. Sort the final file by the email in alphabetical order.\n",
    "\n",
    "Save the cleaned data sets as `./output/merged-identities.csv`.  \n",
    "\n",
    "Do not include the dataframe index in the output csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35a453ce-4e2c-4990-92f7-e44696fda8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE CELL\n",
    "import pandas as pd\n",
    "\n",
    "# CODE START\n",
    "\n",
    "#merge all csvs\n",
    "merged_df = pd.concat(map(pd.read_csv, [\"./output/cleaned-website.csv\", \"./output/cleaned-email.csv\",\"./output/cleaned-manual.csv\"]), ignore_index=True)\n",
    "\n",
    "#remove duplicates\n",
    "merged_df.sort_values(\"email\", inplace = True)\n",
    "merged_df.drop_duplicates(subset =\"email\",keep = 'first', inplace = True)\n",
    "\n",
    "#alphabetical order\n",
    "merged_df.sort_values('email', ascending=False)\n",
    "\n",
    "#add + again\n",
    "merged_df['mobile'] = merged_df['mobile'].astype(str)\n",
    "merged_df.mobile = np.where(merged_df.mobile.str.startswith('63'),'+' + merged_df.mobile,merged_df.mobile)\n",
    "\n",
    "#CSV\n",
    "merged_df.to_csv(\"./output/merged-identities.csv\", index=False)\n",
    "\n",
    "# CODE END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f257b2-2a95-4b06-867b-983b0e6508ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
